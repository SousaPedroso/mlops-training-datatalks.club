{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f349138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_dataset_builder\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"portuguese\")\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0720c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset_builder(\"ruanchaves/b2w-reviews01\").info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ruanchaves/b2w-reviews01\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f85730",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c9faf3b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d86932",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(dataset[\"site_category_lv1\"], dtype=\"str\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(dataset[\"site_category_lv2\"], dtype=\"str\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d818eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(dataset[\"overall_rating\"], dtype=\"int8\"), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73452e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(dataset[\"recommend_to_a_friend\"], dtype=\"str\"), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f778e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.unique(np.array(dataset[\"reviewer_state\"], dtype=\"str\"), return_counts=True)\n",
    "reviews_by_states = {st[0]: st[1] for st in zip(states[0], states[1])}\n",
    "\n",
    "reviews_by_states"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9afb5bdf",
   "metadata": {},
   "source": [
    "Some relations will be visualized considering the following features:\n",
    "- Reviews overall rating\n",
    "- Reviews whose products the client would recommended to someone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reviews(data, relation_column, figsize=(10, 30), hue=None):\n",
    "    _, axes = plt.subplots(5, figsize=figsize)\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        reviews = data.filter(lambda x: x[\"overall_rating\"] == i)\n",
    "    \n",
    "        axes[i-1].set_title(f\"Number of {float(i)} ratings by {relation_column}\")\n",
    "        axes[i-1].set_xticklabels(axes[i-1].get_xticks(), rotation=90)\n",
    "        if hue is None:\n",
    "            sns.countplot(x=reviews[relation_column], ax=axes[i-1],\n",
    "                        order=sorted(np.unique(np.array(reviews[relation_column], dtype=\"str\")))\n",
    "            );\n",
    "        \n",
    "        else:\n",
    "            unique_hue = sorted(np.unique(np.array(reviews[hue], dtype=\"str\")))\n",
    "            sns.countplot(x=reviews[relation_column], hue=reviews[hue], ax=axes[i-1],\n",
    "                        order=sorted(np.unique(np.array(reviews[relation_column], dtype=\"str\"))),\n",
    "                        hue_order=unique_hue\n",
    "            );\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8310b91d",
   "metadata": {},
   "source": [
    "### Reviews and recommendations according to the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews(dataset, \"reviewer_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews(dataset, \"reviewer_state\", hue=\"recommend_to_a_friend\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "555cc632",
   "metadata": {},
   "source": [
    "### Reviews and recommendations according to the category (lv 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews(dataset, \"site_category_lv1\", figsize=(10, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ddd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews(dataset, \"site_category_lv1\", figsize=(10, 90), hue=\"recommend_to_a_friend\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3fc4636",
   "metadata": {},
   "source": [
    "With this overview, we can move on to analyse the content of reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81bca011",
   "metadata": {},
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f176dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(ds):\n",
    "    stemmer = PorterStemmer()\n",
    "    text = ds[\"review_text\"]\n",
    "    word_list = []\n",
    "    \n",
    "    if text is not None:\n",
    "        for word in re.split(r\"[.,!?\\d\\s]+\", text): # process only letters of the alphabet\n",
    "            word = stemmer.stem(word)\n",
    "            if (word not in stopwords) and word != '':\n",
    "                word_list.append(word)\n",
    "    else:\n",
    "        word_list.append(\"None\")\n",
    "\n",
    "    ds[\"tokens_list\"] = word_list\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f768069",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataset.map(tokenize)[\"tokens_list\"]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4646877",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75409a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    num_topics=25,\n",
    "    id2word=dictionary,\n",
    "    alpha=\"auto\",\n",
    "    # passes as 1 just for initial observation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff84e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic in enumerate(lda_model.print_topics(5)):\n",
    "    print(f\"topic {i+1}: {topic}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3da40f98",
   "metadata": {},
   "source": [
    "See the main topic for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {f\"topic_{id}\": [] for id in range(lda_model.num_topics)}\n",
    "\n",
    "for doc in range(len(corpus)):\n",
    "    doc_corpus = corpus[doc]\n",
    "    doc_topics = lda_model.get_document_topics(doc_corpus, 0)\n",
    "    \n",
    "    for topic_id, topic_prob in doc_topics:\n",
    "        topic_dict[f\"topic_{topic_id}\"].append(topic_prob)\n",
    "\n",
    "topic_df = pd.DataFrame(topic_dict)\n",
    "topic_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76ead8ac",
   "metadata": {},
   "source": [
    "How propense are the main topics of a review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dd499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topic(row):\n",
    "    \"\"\"\n",
    "    Get the first ocurrence of a topic\n",
    "    with propensity greather than a defined\n",
    "    threshold\n",
    "    \"\"\"\n",
    "    threshold = 0.50\n",
    "    targ_row = row.loc[row>threshold]\n",
    "\n",
    "    if targ_row.any():\n",
    "        return row.index[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def find_propensity(row):\n",
    "    \"\"\"\n",
    "    Get the propensity for the first ocurrence\n",
    "    of a topic with propensity greather than a defined\n",
    "    threshold\n",
    "    \"\"\"\n",
    "    threshold = 0.50\n",
    "    targ_row = row.loc[row>threshold]\n",
    "\n",
    "    if targ_row.any():\n",
    "        return targ_row.values[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666232c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df[\"topic\"] = topic_df.apply(find_topic, axis=1)\n",
    "topic_df[\"propensity\"] = topic_df.iloc[:, 0:len(topic_df.columns)-1].apply(find_propensity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=topic_df, x=\"topic\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38ee95f1",
   "metadata": {},
   "source": [
    "Elbow method through KMeans inertial to find the optimum number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_squared_dist = []\n",
    "\n",
    "for k in range(1, 25):\n",
    "    km = KMeans(n_clusters=k, n_init='auto')\n",
    "    km = km.fit(topic_df.iloc[:, 0:len(topic_df.columns)-2])\n",
    "    sum_squared_dist.append(km.inertia_)\n",
    "\n",
    "plt.plot(range(1, 25), sum_squared_dist, 'bx-')\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Sum of squared distance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
